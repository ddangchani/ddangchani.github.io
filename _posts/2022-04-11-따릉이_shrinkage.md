---
title: "ë”°ë¦‰ì´ ë°ì´í„° ë¶„ì„í•˜ê¸° (3) Modified Linear Methods"
tags:
- Project
- Shrinkage method
- Linear Regression
- Python
category: Project
use_math: true
header: 
 teaser: /assets/img/ë”°ë¦‰ì´_shrinkage_0.png
---
{% raw %}
## ë”°ë¦‰ì´ ë°ì´í„° ë¶„ì„í•˜ê¸° (3) Modified Linear Methods

ì´ë²ˆ ê¸€ì—ì„œëŠ” Linear regressionì„ ê³„ì† ë‹¤ë£° ê²ƒì¸ë°, ê·¸ì¤‘ì—ì„œë„ regularization methodë‚˜ spline regressionê³¼ ê°™ì€ ë³€í˜•ëœ ë°©ë²•ë“¤ì„ ë‹¤ë£¨ì–´ë³´ê³ ì í•œë‹¤(*ì—­ì‹œ Regression ë¬¸ì œê°€ Linear Modelë¡œ ë‹¤ë£¨ê¸° ìµœì ì¸ë“¯ í•˜ë‹¤*ğŸ¤£). ìš°ì„  Lasso, Ridge ë“±ì„ í¬í•¨í•˜ëŠ” Shrinkage method ë“¤ì„ êµ¬í˜„í•´ë³´ë„ë¡ í•˜ì. ì´ëŸ¬í•œ Linear Methodë“¤ì€ ëª¨ë‘ ì´ì „ì— ì‚¬ìš©í–ˆë˜ `statsmodels` íŒ¨í‚¤ì§€ë¥¼ ì´ìš©í•´ êµ¬í˜„í•  ìˆ˜ ìˆë‹¤.

### Shrinkage Methods

Data loadì™€ train_test splitì˜ ê³¼ì •ì€ [ì´ì „ ê²Œì‹œê¸€](https://ddangchani.github.io/ë”°ë¦‰ì´-ë°ì´í„°-ë¶„ì„í•˜ê¸°-2-Linear-Regression)ë“¤ì„ ì‚´í´ë³´ëŠ” ê²ƒìœ¼ë¡œ ê°ˆìŒí•˜ê³ , ë°”ë¡œ ëª¨ë¸ì„ êµ¬í˜„í•´ë³´ë„ë¡ í•˜ì. ì—¬ê¸°ì„œëŠ” íšŒê·€ê³„ìˆ˜ì˜ Regularizationì„ í†µí•´ ëª¨ë¸ì„ ì„¤ì •í•˜ëŠ” ë°©ë²•ë“¤ì„ ë‹¤ë£° ê²ƒì¸ë°, ìì„¸í•œ ë‚´ìš©ì€ [Linear Regression](https://ddangchani.github.io/Linear-Regression) ê²Œì‹œê¸€ì„ ì‚´í´ë³´ë©´ ë  ê²ƒì´ë‹¤. 

#### Ridge/Lasso/ElasticNet

`statsmodels`íŒ¨í‚¤ì§€ë¡œ ì „ ê²Œì‹œê¸€ì—ì„œ OLS ëª¨ë¸ì„ ë§Œë“  ë’¤, `.fit()` ë©”ì„œë“œë¥¼ ì‚¬ìš©í•´ ëª¨ë¸ì„ fittingí•˜ê³  ì´ë¥¼ ì´ìš©í•´ `summary()`ë¡œ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ íŒŒì•…í•˜ê±°ë‚˜, ëª¨ë¸ì˜ ì„±ëŠ¥ ì§€í‘œë¥¼ attributeë¡œ ë¶ˆëŸ¬ì˜¤ëŠ” ë“±ì˜ ì‘ì—…ì„ í–ˆì—ˆë‹¤. ì´ë•Œ, ì¼ë°˜ì ì¸ `fit` ë©”ì„œë“œ ëŒ€ì‹  `fit_regularized()` ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ë©´ Elastic-Net í˜•íƒœì˜ regularization termì´ ì¶”ê°€ëœ fittingì„ ì§„í–‰í•  ìˆ˜ ìˆë‹¤. ì´ë•Œ parameterë¡œ `alpha=`, `L1_wt=` ì´ ìš”êµ¬ëœë‹¤. ìš°ì„  ì•„ë˜ ì½”ë“œë¥¼ ë³´ë„ë¡ í•˜ì.

```python
# fit_regularized 
ols_lasso = sm.OLS(y_train, X_train).fit_regularized(method="elastic_net", alpha = 0.1, L1_wt=1)
ols_ridge = sm.OLS(y_train, X_train).fit_regularized(method="elastic_net", alpha = 0.1, L1_wt=0)
ols_elnet = sm.OLS(y_train, X_train).fit_regularized(method="elastic_net", alpha = 0.1, L1_wt=0.5)
```

ìœ„ ì½”ë“œì—ì„œ `alpha=0.1`ì€ regularization termì— ê³±í•´ì§„ ìƒìˆ˜, ì¦‰ ê·œì œ ê°•ë„ë¥¼ ì˜ë¯¸í•˜ë©°($\alpha\cdot\Vert\beta\Vert$), `L1_wt=1.0`ì€ Elastic-Netì—ì„œ L1 Regularization Termì„ 1ë§Œí¼ ì‚¬ìš©í•˜ê³  L2 Norm ì„ 0ë§Œí¼ ì‚¬ìš©í•´ Lasso methodë¥¼ ì‚¬ìš©í•¨ì„ ì˜ë¯¸í•œë‹¤. ë°˜ëŒ€ë¡œ, `L1_wt=0`ì€ Ridge methodë¥¼ ì‚¬ìš©í•¨ì„ ì˜ë¯¸í•œë‹¤. ë§ˆì§€ë§‰ ì½”ë“œëŠ” Elastic-Netìœ¼ë¡œ L1 normê³¼ L2 normì— ëª¨ë‘ 0.5ì”©ì˜ ê°€ì¤‘ì¹˜ë¥¼ ë¶€ì—¬í•˜ì—¬ ê·œì œí•˜ëŠ” ê²ƒì„ ì˜ë¯¸í•œë‹¤. 

ê°ê°ì˜ ëª¨ë¸ì€ ì¶”ì •ëœ parameter ê°’ì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ìˆëŠ” `.params` ë©”ì„œë“œë¥¼ ê°€ì§€ë©°, ë‹¤ìŒê³¼ ê°™ì´ í™•ì¸í•  ìˆ˜ ìˆë‹¤.

```py
print(ols_lasso.params)
## result
const         133.952147
hour            4.794684
temp            4.729933
windspeed       5.716406
humidity       -1.245661
visibility     -0.035364
ozone           0.000000
pm10           -0.634140
pm2_5          -0.639569
precip_1.0    -58.274955
dtype: float64
```

ì´ë•Œ ëª¨ë¸ì—ì„œ alphaê°’ì€ hyperparameterì´ë¯€ë¡œ, alpha ê°’ì„ ì¡°ì •í•˜ë©° ê° ì˜ˆì¸¡ë³€ìˆ˜ë“¤ì˜ coefficientì— ì–´ë– í•œ ì˜í–¥ì„ ë¯¸ì¹˜ëŠ”ì§€ íŒŒì•…í•´ë³´ë„ë¡ í•˜ì. ë‹¤ìŒ ì½”ë“œëŠ” alpha ê°’ì„ $10^{-3}$ë¶€í„° $10^1$ê¹Œì§€ ì´ 5ê°œ ê°’ì„ ì·¨í•  ìˆ˜ ìˆê²Œë” í•˜ì—¬ ê° alphaê°’ì— ëŒ€í•œ ridge regressionì˜ ê° íšŒê·€ê³„ìˆ˜ë¥¼ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë°˜í™˜í•œë‹¤.

```python
# changing alpha - ridge
alpha = np.logspace(-3,1,5) # range of alpha(exponential)
data = []
for i, a in enumerate(alpha): 
    ridge = sm.OLS(y_train, X_train).fit_regularized(method = 'elastic_net', L1_wt = 0, alpha = a)
    data.append(ridge.params)
df_ridge = pd.DataFrame(data, index = alpha).T.round(3)
df_ridge.index = X_train.columns
print(df_ridge)
```

ê²°ê³¼ëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤.

|            |   0.001 |   0.010 |   0.100 |  1.000 | 10.000 |
| ---------: | ------: | ------: | ------: | -----: | ------ |
|      const | -47.021 | -19.137 |  -2.610 | -0.172 | 0.031  |
|       hour |   4.570 |   4.542 |   4.497 |  4.631 | 4.393  |
|       temp |   5.831 |   5.658 |   5.558 |  5.548 | 4.641  |
|  windspeed |   8.344 |   8.056 |   7.287 |  4.580 | 1.369  |
|   humidity |  -0.242 |  -0.424 |  -0.561 | -0.597 | -0.591 |
| visibility |   0.008 |   0.002 |   0.000 |  0.002 | 0.013  |
|      ozone |  52.863 |   6.231 |   0.684 |  0.095 | 0.020  |
|       pm10 |  -0.331 |  -0.368 |  -0.381 | -0.356 | -0.281 |
|      pm2_5 |   0.165 |   0.067 |   0.011 |  0.009 | 0.174  |
| precip_1.0 | -59.797 | -42.783 | -11.126 | -1.313 | -0.127 |

alpha ê°’ì´ ì»¤ì§ˆìˆ˜ë¡ ê° íšŒê·€ê³„ìˆ˜ê°€ 0ì— ìˆ˜ë ´í•¨ì„ í™•ì¸í•  ìˆ˜ ìˆìœ¼ë©°, ì´ë²ˆì—ëŠ” plotì„ í†µí•´ ridge, lasso, elastic-net($\alpha=0.5$) ì¼ ë•Œì˜ ë³€í™”ë¥¼ ë¹„êµí•´ë³´ë„ë¡ í•˜ì.

```py
# Plot : coef vs. alpha
fig = plt.figure(figsize = (10,20))
ax1 = plt.subplot(3,1,1)
plt.semilogx(df_ridge.T) # ridge
plt.xticks(np.logspace(-3,1,5), labels=np.log10(alpha))
plt.title('Ridge')

ax2 = plt.subplot(3,1,2)
plt.semilogx(df_lasso.T) # lasso
plt.xticks(np.logspace(-3,1,5), labels=np.log10(alpha))
plt.title('Lasso')

ax3 = plt.subplot(3,1,3)
plt.semilogx(df_elnet.T) # elnet
plt.xticks(np.logspace(-3,1,5), labels=np.log10(alpha))
plt.title('Elnet')
```

ìœ„ ì½”ë“œë¥¼ ì‹¤í–‰í•˜ë©´, ë‹¤ìŒê³¼ ê°™ì€ ì„¸ ê·¸ë˜í”„ë¥¼ ì–»ì„ ìˆ˜ ìˆëŠ”ë°, Lasso methodê°€ ê³„ìˆ˜ì˜ ìˆ˜ë ´ì´ ê°€ì¥ ëŠë¦¬ë©°, Ridgeê°€ ê°€ì¥ ë¹ ë¥´ê²Œ ìˆ˜ë ´í•¨ì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.

 <img src="/assets/img/ë”°ë¦‰ì´_shrinkage_0.png" alt="á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2022-04-11 á„‹á…©á„’á…® 4.07.18"/>

ë°˜ë©´, ìµœì ì˜ alpha ê°’ì„ ì°¾ëŠ” ê²ƒì€ train dataê°€ ì•„ë‹Œ validation dataê°€ ê¸°ì¤€ì´ ë˜ì–´ì•¼ í•˜ë¯€ë¡œ, validation dataë¥¼ ì´ìš©í•´ ê°„ë‹¨í•œ hyperparameter tuningì„ í•´ë³´ë©´ ë‹¤ìŒê³¼ ê°™ë‹¤.

```py
# Tune alpha with validation
from sklearn.metrics import mean_squared_error
def tune_alpha(y, X, y_val, X_val, wt_list):
    alpha = np.logspace(-3,1,5) # 10^-3 to 10^1 by sqrt(10)
    data = []
    for wt in wt_list:
        data_wt = []
        for i, a in enumerate(alpha):
            model = sm.OLS(y, X).fit_regularized(method='elastic_net', alpha = a, L1_wt=wt)
            pred = model.predict(X_val)
            rmse = np.sqrt(mean_squared_error(y_val, pred)).round(3)
            data_wt.append(rmse)
        data.append(data_wt)
    df = pd.DataFrame(data, index=wt_list)
    df.columns = alpha
    return df

tune_alpha(y_train, X_train, y_val, X_val, wt_list=[1, 0.5, 0]) # lasso to ridge
```

ê²°ê³¼ëŠ” ë‹¤ìŒê³¼ ê°™ì€ë°, ê° í–‰ì€ `L1_wt` ì¦‰ elastic-netì˜ í˜•íƒœë¥¼ ì˜ë¯¸í•˜ê³  ê° ì—´ì€ hyperparameterì¸ ê·œì œ ê°•ë„ alpha ê°’ì„ ì˜ë¯¸í•˜ë©° ê° ì…€ì˜ ë°ì´í„°ëŠ” validation dataì— ëŒ€í•œ rmse ê°’ì„ ì˜ë¯¸í•œë‹¤.

|      |  0.001 |   0.01 |    0.1 |      1 |     10 |
| ---: | -----: | -----: | -----: | -----: | -----: |
|  1.0 | 53.806 | 53.830 | 54.141 | 53.682 | 53.168 |
|  0.5 | 54.171 | 54.114 | 54.388 | 53.496 | 53.287 |
|  0.0 | 53.244 | 53.110 | 53.496 | 53.349 | 53.480 |

ìì„¸í•œ íŠœë‹ì„ í•´ë³´ê¸° ìœ„í•´ ì´ë²ˆì—ëŠ” plotì„ ê·¸ë ¤ë³´ê³ , alphaì˜ ê·¸ë¦¬ë“œë¥¼ ë” ì˜ê²Œ íƒìƒ‰í•´ë³´ë„ë¡ í•˜ì. ìš°ì„  ì•ì„  í•¨ìˆ˜ `tune_alpha()`ë¥¼ ì•½ê°„ ìˆ˜ì •í•´ `wt_list=[1,0.5,0]` ì€ ê·¸ëŒ€ë¡œ ë‘ê³  alphaê°’ë“¤ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë°›ëŠ” í•¨ìˆ˜ë¡œ ë³€ê²½í–ˆë‹¤(ì½”ë“œëŠ” ìƒëµ, github full code ì°¸ê³ ). ì´í›„ ì•„ë˜ì™€ ê°™ì´ ë°ì´í„°í”„ë ˆì„ì„ êµ¬í•˜ê³  plotì„ ìƒì„±í–ˆë‹¤.

```py
# Tune alpha plot
alpha_ls = np.power(10,(np.arange(-4, 1, 0.5))) # 10 grid of alpha
df = tune_alpha(y_train, X_train, y_val, X_val, alpha_ls=alpha_ls)

fig = plt.figure(figsize=(10,10))
plt.semilogx(df, label=['Lasso','Elastic-Net','Ridge'])
plt.legend(loc='upper right', title = 'Model')
plt.xticks(alpha_ls, labels=np.log10(alpha_ls))
plt.ylabel('RMSE')
plt.xlabel('alpha(10^x)')
plt.title('RMSE vs. alpha for 3 model')
plt.savefig('plots/rmse_vs_alpha.png', facecolor='white', transparent=False)
```

ê²°ê³¼ëŠ” ì•„ë˜ì™€ ê°™ì€ë°, ì´ë¥¼ ë³´ë©´ Lassoì˜ ê²½ìš° $\alpha=1.0$ì—ì„œ ì „ì—­ ìµœì†Œê°€ ë°œìƒí•˜ê³ , Elastic-Netê³¼ RidgeëŠ” $\alpha=\sqrt{10}$ì—ì„œ ìµœì†Œì¸ ê²ƒ ì²˜ëŸ¼ ë³´ì´ì§€ë§Œì„œë„ Ridgeì˜ ê²½ìš°ëŠ” $10^{-2}$ì—ì„œ ì „ì—­ ìµœì†Œê°€ ëœë‹¤. ì„¸ ëª¨ë¸ì„ ëª¨ë‘ ê³ ë ¤í•œë‹¤ë©´, Ridgeì—ì„œ $\alpha=0.01$ì¸ ê²½ìš°ê°€ ê°€ì¥ ë‚®ì€ validation RMSEë¥¼ ê°€ì§€ë¯€ë¡œ ì´ë¥¼ íƒí•˜ëŠ” ê²ƒì´ ì¢‹ì•„ë³´ì¸ë‹¤.

<img src="/assets/img/ë”°ë¦‰ì´_shrinkage_1.png" alt="á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2022-04-11 á„‹á…©á„’á…® 7.19.09"/>

#### Least Angle Regression

LARSë¡œ ë¶ˆë¦¬ëŠ” [Least Angle Regression](https://ddangchani.github.io/linear%20model/linearreg1/)ì€ ê³ ì°¨ì› ë°ì´í„°ì— ëŒ€í•´ íš¨ê³¼ì ì¸ ë°©ë²•ì¸ë°, forward-stepwise regression(ì´ì „ í¬ìŠ¤íŠ¸ ì°¸ê³ )ì™€ ìœ ì‚¬í•˜ê²Œ ë³€ìˆ˜ë“¤ì„ í•˜ë‚˜ì”© ì¶”ê°€í•˜ë©´ì„œ ëª¨í˜•ì„ ìƒì„±í•´ë‚˜ê°„ë‹¤(ìì„¸í•œ ì•Œê³ ë¦¬ì¦˜ì€ ë§í¬ ì°¸ê³ ). ë‹¤ë§Œ, high-dimensional dataì—ì„œ íŠ¹ë³„íˆ ê³„ì‚°ì ìœ¼ë¡œ ìœ ìš©í•œ ê²ƒì´ë¯€ë¡œ(*ì¶”í›„ ê³ ì°¨ì›ë°ì´í„° ìƒ˜í”Œì„ êµ¬í•˜ë©´ ì—°êµ¬í•´ë³´ë„ë¡ í•˜ê² ë‹¤*), ì—¬ê¸°ì„œëŠ” ì‘ë™ ì½”ë“œë§Œ íŒŒì•…í•´ë³´ë„ë¡ í•˜ì. ì•ˆíƒ€ê¹ê²Œë„, `statsmodels` íŒ¨í‚¤ì§€ëŠ” LARSë¥¼ ì§ì ‘ ìˆ˜í–‰í•  ìˆ˜ ìˆëŠ” ëª¨ë“ˆì„ ì œê³µí•˜ì§€ ì•Šìœ¼ë¯€ë¡œ ëŒ€í‘œì ì¸ ë¨¸ì‹ ëŸ¬ë‹ íŒ¨í‚¤ì§€ `scikit-learn`ì„ ì´ìš©í•´ë³´ë„ë¡ í•˜ì. `sklearn.linear_model`ì˜ `Lars`ë¥¼ ì´ìš©í•´ ë‹¤ìŒ ì½”ë“œì™€ ê°™ì´ Lars ëª¨ë¸ì„ ìƒì„±í•˜ê³  validation dataì— ëŒ€í•œ RMSEë¥¼ ê³„ì‚°í•  ìˆ˜ ìˆë‹¤.

```python
# LARS
from sklearn import linear_model
reg = linear_model.Lars(n_nonzero_coefs=5, fit_intercept=True, normalize=False)
reg.fit(X_train, y_train)
pred_val = reg.predict(X_val)
rmse = np.sqrt(mean_squared_error(y_val, pred_val)).round(3)
print(rmse) # 53.242
```

LARS ì•Œê³ ë¦¬ì¦˜ì€ ë³€ìˆ˜ë¥¼ í•˜ë‚˜ì”© fittingí•˜ë©° ì¤‘ê°„ì— 0ì´ ë˜ëŠ” íšŒê·€ê³„ìˆ˜ê°€ ì œê±°ë˜ëŠ” ë°©ì‹ì¸ë°, ì—¬ê¸°ì„œ `n_nonzero_coefs=10`ì€ 0ì´ ë˜ëŠ” ë³€ìˆ˜ë“¤ì„ ì œê±°í•˜ê³  ë‚¨ì€ nonzero ë³€ìˆ˜ë“¤ì„ ëª‡ ê°œë¡œ ì„¤ì •í•  ê²ƒì¸ì§€ ì •í•˜ëŠ” hyperparmeterì˜ ì¼ì¢…ì´ë‹¤. ë˜í•œ `reg.coef_path_` attributeëŠ” Lars ì•Œê³ ë¦¬ì¦˜ì´ ì–´ë–»ê²Œ ì§„í–‰ë˜ëŠ”ì§€, ì¦‰ íšŒê·€ê³„ìˆ˜ê°€ ê° ë‹¨ê³„ë§ˆë‹¤ ì–´ë–»ê²Œ ë³€í•˜ëŠ”ì§€ í™•ì¸í•  ìˆ˜ ìˆê²Œë” í•´ì¤€ë‹¤. ë‹¤ìŒ ì½”ë“œ

```py
pd.DataFrame(reg.coef_path_, index = X_train.columns).round(3)
```

ë¥¼ í†µí•´ ê° ë³€ìˆ˜(í–‰)ê°€ ê° ë‹¨ê³„(ì—´)ë§ˆë‹¤ ì–´ë–¤ íšŒê·€ê³„ìˆ˜ë¥¼ ê°–ëŠ”ì§€ í™•ì¸í•  ìˆ˜ ìˆë‹¤. ê²°ê³¼ëŠ” ì•„ë˜ í‘œì™€ ê°™ì€ë°, ê°€ì¥ ì²« ë‹¨ê³„ì—ì„œ visibilityê°€ ë°˜ì‘ë³€ìˆ˜ì™€ ê°€ì¥ ë†’ì€ ìƒê´€ê´€ê³„ë¥¼ ê°€ì§€ê²Œ ë˜ì–´ ì´ˆê¸° ë³€ìˆ˜ë¡œ ì„ íƒë˜ì—ˆê³ , ì´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì•Œê³ ë¦¬ì¦˜ì´ ì§„í–‰ë˜ë©° ê³„ìˆ˜ê°€ 0ì´ ì•„ë‹Œ ë³€ìˆ˜ê°€ hour, temp, humidity, visibility, pm10ìœ¼ë¡œ 5ê°œê°€ ë„ì¶œëœ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.

|            |    0 |     1 |      2 |      3 |      4 | 5      |
| ---------: | ---: | ----: | -----: | -----: | -----: | ------ |
|      const |  0.0 | 0.000 |  0.000 |  0.000 |  0.000 | 0.000  |
|       hour |  0.0 | 0.000 |  0.000 |  1.771 |  2.639 | 4.904  |
|       temp |  0.0 | 0.000 |  0.000 |  0.000 |  0.000 | 5.799  |
|  windspeed |  0.0 | 0.000 |  0.000 |  0.000 |  0.000 | 0.000  |
|   humidity |  0.0 | 0.000 | -0.579 | -0.694 | -0.834 | -0.516 |
| visibility |  0.0 | 0.045 |  0.034 |  0.028 |  0.021 | 0.008  |
|      ozone |  0.0 | 0.000 |  0.000 |  0.000 |  0.000 | 0.000  |
|       pm10 |  0.0 | 0.000 |  0.000 |  0.000 | -0.095 | -0.270 |
|      pm2_5 |  0.0 | 0.000 |  0.000 |  0.000 |  0.000 | 0.000  |
| precip_1.0 |  0.0 | 0.000 |  0.000 |  0.000 |  0.000 | 0.000  |



ğŸ–¥ Full code on Github : https://github.com/ddangchani/project_ddareungi

# References

- https://datascienceschool.net/03%20machine%20learning/06.05%20ì •ê·œí™”%20ì„ í˜•íšŒê·€.html
{% endraw %}