---
title: "Markov Chain Monte Carlo"
tags:
- Statistics
- MCMC
- Markov Chain
- Monte Carlo
category: Statistics
use_math: true
header: 
 teaser: /assets/img/MCMC.assets/MCMC_0.png
---
{% raw %}
# Markov Chain Monte Carlo

MCMCë¼ê³ ë„ í•˜ëŠ” Markov Chain Monte Carlo ê¸°ë²•ì€ í™•ë¥ ë¶„í¬ì—ì„œ ìƒ˜í”Œì„ ì¶”ì¶œí•˜ëŠ” ì—¬ëŸ¬ ì¢…ë¥˜ì˜ ì•Œê³ ë¦¬ì¦˜ì„ ì¼ì»«ëŠ”ë‹¤. ë‹¤ì–‘í•œ ë¨¸ì‹ ëŸ¬ë‹ ì´ë¡ ë“¤ì´ ë“±ì¥í•˜ë©°, ê¸°ì¡´ í†µê³„í•™ì—ì„œ ë‹¤ë£° ìˆ˜ ì—†ì„ ì •ë„ì˜ ìˆ˜ë§Œ-ìˆ˜ë°±ë§Œ ê°œì˜ ë³€ìˆ˜ ë° íŒŒë¼ë¯¸í„°ë¥¼ ì‚¬ìš©í•˜ëŠ” ëª¨ë¸ë“¤ ì—­ì‹œ ë“±ì¥í–ˆê³ , íŠ¹íˆ ì‹ ê²½ë§ê³¼ ê°™ì€ ëª¨ë¸ë“¤ì€ ë„ˆë¬´ë‚˜ë„ ë„ë¦¬ ì‚¬ìš©ë˜ê³  ìˆë‹¤. í•˜ì§€ë§Œ ê·¸ëŸ¬í•œ ê³ ì°¨ì› ëª¨ë¸ë“¤ì— ëŒ€í•´ ìƒ˜í”Œë§ì„ ìˆ˜í–‰í•˜ê±°ë‚˜, ê¸°ëŒ“ê°’ ë“± ì ë¶„ê°’ì„ êµ¬í•˜ëŠ” ê³¼ì •ì€ ê¸°ì¡´ì˜ ë‹¤ì¤‘ì ë¶„ìœ¼ë¡œëŠ” ë¶ˆê°€ëŠ¥í•˜ë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ëª¬í…Œì¹´ë¥¼ë¡œ ë°©ë²•, ê·¸ì¤‘ì—ì„œë„ ë§ˆì½”í”„ ì²´ì¸ì„ ì´ìš©í•œ MCMCê°€ ì‚¬ìš©ë˜ë©° ì´ëŠ” ê·¼ë˜ í†µê³„í•™ ë° ë¨¸ì‹ ëŸ¬ë‹ ë¶„ì•¼ì—ì„œ ë§¤ìš° ì¤‘ìš”í•œ ë¶€ë¶„ì„ ì°¨ì§€í•œë‹¤. 

## Markov Chain

Markov Chainì€ ì‹œê°„($t$)ì— ë”°ë¼ ë³€í™”í•˜ëŠ” ì‹œìŠ¤í…œ(ê³„)ì˜ ìƒíƒœë¥¼ ì„¤ëª…í•˜ê¸° ìœ„í•œ ê°œë…ì´ë‹¤. ì–´ë–¤ ì‹œìŠ¤í…œì˜ ìƒíƒœê°€ Aì—ì„œ Bë¡œ, Bì—ì„œ Cë¡œ ì‹œê°„($t=0,1,2,\dots$)ì— ë”°ë¼ ë³€í™”í•˜ëŠ” ê³¼ì •ì´ ê°ê° í™•ë¥ ë¡œ ì£¼ì–´ì§€ëŠ” ê²ƒì„ ì˜ë¯¸í•œë‹¤. ë§Œì¼ ì‹œê°„ $t$ì—ì„œì˜ ìƒíƒœë¥¼ ëª¨ë‘ í¬í•¨í•˜ëŠ” ì¶©ë¶„í†µê³„ëŸ‰ $x_t$ê°€ ì¡´ì¬í•˜ë©°, ëª¨ë“  ê³¼ê±°ì˜ ìƒíƒœê°€ ì´ì— í¬í•¨ëœë‹¤ë©´ ì´ë¥¼ **markov property**ë¼ê³  í•œë‹¤. ì¦‰, ë‹¤ìŒì„ ì˜ë¯¸í•œë‹¤.

$$

p(x_{t+\tau}\vert x_t,x_{1:t-1}) = p(x_{t+\tau}\vert x_t)

$$

Markov propertyê°€ ë§Œì¡±ë  ê²½ìš° ìœ í•œí•œ í™•ë¥ ê³¼ì •ì—´ì„ ë‹¤ìŒê³¼ ê°™ì´ ì“¸ ìˆ˜ ìˆëŠ”ë°,

$$

p(x_{1:T}) = p(x_1)\prod_{t=2}^Tp(x_t\vert x_{t-1})

$$

ì´ë¥¼ **Markov Chain** ì´ë¼ê³  í•œë‹¤.

### Stationary Markov Chain

ë‹¤ìŒê³¼ ê°™ì´ time-shiftê°€ ì´ë£¨ì–´ì ¸ë„ joint distributionì´ ì¼ì¹˜í•˜ëŠ” markov chainì„ **stationary markov chain**ì´ë¼ê³  í•œë‹¤.(stationary : ì •ìƒì„±)

$$

\Pr(x_0 = z_0, x_1=z_1,\ldots,x_k = z_k)=\Pr(x_n=z_0,\ldots,x_{k+n}=z_k)

$$

ë˜í•œ stationary markov chainì—ì„œì˜ marginal distribution, ì¦‰ $\Pr(x_0=x)$ì„ í•´ë‹¹ ë§ˆì½”í”„ ì²´ì¸ì˜ stationary distributionì´ë¼ê³  í•œë‹¤.

## Monte Carlo Integration

ëª¬í…Œì¹´ë¥¼ë¡œ ì ë¶„ì€ í™•ë¥ ë³€ìˆ˜ì˜ ê¸°ëŒ“ê°’, ì¦‰ ì ë¶„ê°’ì„ random samplingìœ¼ë¡œ ê·¼ì‚¬í•˜ëŠ” ë°©ë²•ì´ë‹¤.

$$

\mathrm E[f(x)] = \int f(x)p(x)dx

$$

í™•ë¥ ë³€ìˆ˜ $X\in\mathbb R^n$ ì™€ target distribution $p(X)$ì— ëŒ€í•´ ê¸°ëŒ“ê°’ì„ êµ¬í•˜ê¸° ìœ„í•´ì„œëŠ” ìœ„ì™€ ê°™ì€ ì ë¶„ì„ ê³„ì‚°í•´ì•¼ í•œë‹¤. ê·¸ëŸ¬ë‚˜, ë•Œë¡œëŠ” ì ë¶„ì˜ closed formì„ êµ¬í•˜ê¸° ì–´ë µê±°ë‚˜ ë°ì´í„°ê°€ ê³ ì°¨ì›ì¸ ê²½ìš° ê³„ì‚° ê³¼ì •ì´ ë§¤ìš° ë³µì¡í•˜ì—¬ computation cost ë¬¸ì œê°€ ë°œìƒí•  ìˆ˜ ìˆë‹¤. ì´ë¥¼ ê·¹ë³µí•˜ê¸° ìœ„í•´ ë‹¤ìŒê³¼ ê°™ì´ ì ë¶„ê°’ì„ ê·¼ì‚¬í•˜ëŠ” ë°©ë²•ì„ **Monte Carlo integration**ì´ë¼ê³  í•œë‹¤.

$$

\mathrm E[f(x)]\approx {1\over n_s}\sum_{n=1}^{n_s} f(x_n)

$$

## MCMC

Markov Chain Monte Carlo(ì´í•˜ MCMC)ëŠ” ëª¬í…Œì¹´ë¥¼ë¡œ ë°©ë²• ì¤‘ì—ì„œ ê°€ì¥ ë„ë¦¬ ì‚¬ìš©ë˜ëŠ” ê¸°ë²• ì¤‘ í•˜ë‚˜ì´ë‹¤. MCMCì˜ ê¸°ë³¸ì ì¸ ì•„ì´ë””ì–´ëŠ” ìƒíƒœê³µê°„ $\mathcal X$ì—ì„œ target density $p^{\ast}(x)$ë¥¼ stationary distributionìœ¼ë¡œ í•˜ëŠ” ë§ˆì½”í”„ ì²´ì¸ì„ êµ¬ì„±í•˜ëŠ” ê²ƒì´ë‹¤. ì´ëŠ” ìƒíƒœê³µê°„ì—ì„œ ê° ìƒíƒœ $x$ì— ë¨¸ë¬¸ ì‹œê°„($t$)ì˜ ë¹„ìœ¨ì´ $p^{\ast}(x)$ì— ë¹„ë¡€í•˜ë„ë¡ random walkë¥¼ ì§„í–‰í•˜ëŠ” ê²ƒì„ ì˜ë¯¸í•œë‹¤.

ì´ëŸ¬í•œ random walkë¡œë¶€í„° ìƒ˜í”Œ $x_0,x_1,\ldots$ë¥¼ ì¶”ì¶œí•˜ì—¬ í™•ë¥ ì¸¡ë„ $p^{\ast}$ì— ëŒ€í•´ ëª¬í…Œì¹´ë¥¼ë¡œ ì ë¶„ì„ ì‹¤í–‰í•  ìˆ˜ ìˆë‹¤. ì´ë•Œ ì¤‘ìš”í•œ ê²ƒì€, random walkì˜ ì´ˆê¸° ê³¼ì •ì€ sampleì˜ ê°œìˆ˜ê°€ ì ê¸° ë•Œë¬¸ì— ì´ë•Œì—ëŠ” ì •ìƒì„±(stationarity)ì´ ë³´ì¥ë˜ì§€ ì•ŠëŠ”ë‹¤. ë”°ë¼ì„œ ì •ìƒì„±ì— ì´ë¥´ëŠ” ì‹œê°„ë™ì•ˆì˜ ìƒ˜í”Œì€ ì œê±°í•˜ëŠ” ê²ƒì´ ë§ìœ¼ë©°, ì •ìƒì„±ì— ì´ë¥´ê¸°ê¹Œì§€ì˜ ì‹œê°„ì„ burn-in timeì´ë¼ê³ ë„ í•œë‹¤.

### MH(Metropolis Hastings) Algorithm

MCMC ì•Œê³ ë¦¬ì¦˜ì˜ ê°€ì¥ ëŒ€í‘œì ì¸ ê²ƒ ì¤‘ í•˜ë‚˜ì¸ MH ì•Œê³ ë¦¬ì¦˜ì— ëŒ€í•´ ì‚´í´ë³´ë„ë¡ í•˜ì. ì•ì„œ MCMCì˜ ê¸°ë³¸ ì›ë¦¬ëŠ” ìƒíƒœê°„ ì´ë™ì´ ì •ìƒë¶„í¬($p^{\ast}$)ì— ê·¼ê±°í•´ ì´ë£¨ì–´ì§„ë‹¤ê³  ì„¤ëª…í•œ ë°” ìˆë‹¤. MH ì•Œê³ ë¦¬ì¦˜ì—ì„œëŠ” $x\to x'$ì˜ ìƒíƒœì´ë™ì´ í™•ë¥  $q(x'\vert \;x)$ ë¡œ ì´ë™í•˜ëŠ”ë°, $q$ëŠ” **proposal distribution** ì´ë¼ê³  í•œë‹¤(ìƒˆë¡œìš´ ìƒíƒœ $x'$ë¡œ ì›€ì§ì¼ ê²ƒì„ **ì œì•ˆ**ë°›ëŠ”ë‹¤ëŠ” ì˜ë¯¸ë¡œ proposalì´ë¼ê³  í•˜ëŠ” ê²ƒ ê°™ë‹¤ğŸ˜ƒ).

ì•Œê³ ë¦¬ì¦˜ì—ì„œ $x\to x'$ë¡œì˜ ìƒíƒœ ì´ë™ì„ ì œì•ˆë°›ìœ¼ë©´, ê·¸ ì œì•ˆì„ accept í•  ê²ƒì¸ì§€ ê²°ì •í•˜ëŠ” ê³¼ì •ì´ ì¡´ì¬í•œë‹¤. Acceptê°€ ì´ë£¨ì–´ì§€ë©´ $x'$ë¥¼ ìƒˆë¡œìš´ ìƒ˜í”Œë¡œ ì‚¬ìš©í•˜ê³ , ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ ê¸°ì¡´ ìƒ˜í”Œì„ ë°˜ë³µí•´ì„œ ì¶”ì¶œí•œë‹¤. ì „ì²´ ì•Œê³ ë¦¬ì¦˜ì€ ë‹¤ìŒê³¼ ê°™ë‹¤.

> Metropolis Hastings Algorithm
>
> 1. Initialize $x^0$
>
> 2. ê° ë‹¨ê³„ $s=0,1,2\ldots$ ì— ëŒ€í•´ ë‹¤ìŒ ê³¼ì •ì„ ë°˜ë³µí•œë‹¤:
>
>    1) $x=x^s$
> 
>    2) $x'\sim q(x'\vert x)$ ìœ¼ë¡œë¶€í„° ìƒˆë¡œìš´ ìƒ˜í”Œì„ ì¶”ì¶œí•œë‹¤.
> 
>    3) Acceptance probabilityë¥¼ ê³„ì‚°í•œë‹¤.
>
>    $$
>    \alpha=\frac{\tilde p(x')q(x\vert x')}{\tilde p(x)q(x'\vert x)}\\
>    A=\min(1,\alpha)
>    $$
>
>    4) $u\sim U(0,1)$ ìœ¼ë¡œë¶€í„° ìƒ˜í”Œì„ ì¶”ì¶œí•œë‹¤.
> 
>    5) ìƒˆë¡œìš´ ìƒ˜í”Œ $x^{s+1}$ì„ ë‹¤ìŒê³¼ ê°™ì´ ì •ì˜í•œë‹¤.
>
>    $$
>    x^{s+1}=\begin{cases}x'\;\;:\;\mathrm{if} \; u\leq A\;\;(\mathrm{accept}) \\
>    x^s\;\;:\;\mathrm{if}\; u>A\;\;(\mathrm{reject})
>          
>    \end{cases}
>    $$

ì—¬ê¸°ì„œ $p^{\ast}(x) = \tilde p(x)/Z$ ë¡œ $\tilde p $ëŠ” ì •ê·œí™”ë˜ì§€ ì•Šì€ ë¶„í¬ë¥¼, $p^{\ast}$ëŠ” ì •ê·œí™”ìƒìˆ˜ë¥¼ ì´ìš©í•˜ì—¬ ì •ê·œí™”ëœ ë¶„í¬ë¥¼ ê°ê° ë‚˜íƒ€ë‚¸ë‹¤.

MH ì•Œê³ ë¦¬ì¦˜ì´ ì‹¤ì œë¡œ ì •ìƒí™•ë¥ ë¶„í¬ $p^{\ast}$ë¡œë¶€í„° ìƒ˜í”Œì„ ìƒì„±í•œë‹¤ëŠ” ê²ƒì„ ì¦ëª…í•˜ëŠ” ìì„¸í•œ ê³¼ì •ì€ ì°¸ê³  êµì¬ë¥¼ ì‚´í´ë³´ë©´ ì¢‹ì„ ê²ƒ ê°™ë‹¤. ì•„ë˜ëŠ” ì‹¤ì œë¡œ MH ì•Œê³ ë¦¬ì¦˜ì„ ì´ìš©í•œ sample generatingì„ ì½”ë”©í•´ë³´ë„ë¡ í•˜ê² ë‹¤.

### Code

ì•ì„œ ì‚´í´ë³¸ MH ì•Œê³ ë¦¬ì¦˜ì—ì„œ, proposal distributionì„ simple normal distribution $N(0,1)$ ë¡œ í•˜ëŠ” ì½”ë“œë¥¼ êµ¬í˜„í•´ë³´ë„ë¡ í•˜ì. í•„ìš”í•œ íŒ¨í‚¤ì§€ë“¤ì€ ë‹¤ìŒê³¼ ê°™ë‹¤.

```py
import numpy as np
import scipy.stats as ss
import matplotlib.pyplot as plt
```

ìƒ˜í”Œë§í•˜ê³ ì í•  íƒ€ê²Ÿ ë¶„í¬ë¥¼ ì´ë²ˆì—ëŠ” í‰ê· ì´ 5, í‘œì¤€í¸ì°¨ê°€ 10ì¸ ì •ê·œë¶„í¬ë¡œ í•˜ê³ , ë‹¤ìŒê³¼ ê°™ì´ random variableì„ `scipy.stats` ìœ¼ë¡œ ì„¤ì •í–ˆë‹¤.

```py
# Parameter
MU = 10.0
SIGMA = 5.0
target = ss.norm(loc=MU, scale=SIGMA) # target distribution
```

MH ì•Œê³ ë¦¬ì¦˜ì€ ì•„ë˜ì™€ ê°™ì€ ì½”ë“œë¡œ ì§„í–‰ì‹œì¼°ë‹¤. ì´ ë°˜ë³µíšŸìˆ˜ëŠ” 10000íšŒë¡œ ë‘” ë’¤ ì´ˆê¸°ê°’ì€ ì„ì˜ë¡œ ì„¤ì •í–ˆê³ (3.0, randomìœ¼ë¡œ ìƒì„±í•´ë„ ëœë‹¤) ê° ë°˜ë³µë¬¸ì˜ ë‹¨ê³„ì—ì„œ ì´ì „ stateì— proposal distributionì„ ë”í•œ ê°’ `x_proposed`ìœ¼ë¡œ $A$ ê°’ì„ ê³„ì‚°í•˜ì—¬, uniform distributionì—ì„œ ì¶”ì¶œí•œ $u$ì™€ ë¹„êµí•œ ë’¤ ìƒˆ ë‹¨ê³„ì˜ stateë¥¼ ì—…ë°ì´íŠ¸ í•˜ëŠ” ë°©ì‹ì´ë‹¤.

```python
# Rep count = 10000
x = np.zeros(shape=10000)

# initialize x_0
x[0] = 3.0

for i in range(1,10000):
    x_t = x[i-1]
    x_proposed = x_t + np.random.standard_normal(1)[0] # Proposal Distribution
    A = min(1, target.pdf(x_proposed) / target.pdf(x_t)) # Since q is symmetric

    u = np.random.uniform(size=1)[0] # u from Uniform dist

    if u <= A : # Accept
        x[i] = x_proposed
    else:
        x[i] = x_t
```

Plottingí•œ ê²°ê³¼ëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤.

![á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2022-09-11 á„‹á…©á„’á…® 4.04.32](/assets/img/MCMC.assets/MCMC_0.png){: .align-center}



# References

- Probabilistic Machine Learning : Advanced Topics, Murphy.
- Code at github : https://github.com/ddangchani/Velog/blob/main/Statistical%20Learning/MCMC.ipynb
{% endraw %}