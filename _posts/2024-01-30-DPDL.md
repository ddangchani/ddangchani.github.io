---
title: "[Paper Review] Deep Learning with Differential Privacy"
tags: 
- Paper Review
- Deep Learning
- Differential Privacy
category: ""
use_math: true
---

# DL with DP

이번에 읽은 논문은 Deep Learning with Differential Privacy이다. 이 논문은 Deep Learning을 Differential Privacy를 만족하도록 학습하는 이론적인 방법을 제시한다. 이에 대해 간단히 정리하고자 한다.

## Definitions

### Differential Privacy

Randomized mechanism<sup>algorithm</sup> $\mathcal{M}:\mathcal{D}\to \mathbb{R}$ 이 데이터셋의 정의역 $\mathcal{D}$ 와 output range $\mathcal{R}$ 를 갖는다고 하자. 이때 메커니즘 $\mathcal{M}$ 이 $(\epsilon-\delta)$-DP인 것은 임의의 두 [이웃]({% post_url 2024-01-02-Differential-Privacy %})하는 데이터셋 $D,D'\in\mathcal{D}$ 에 대해

$$
\Pr (\mathcal{M}(D)\in S) \le e^{\epsilon}\Pr (\mathcal{M}(D')\in S)+\delta
$$

$\forall S\subseteq \mathbb{R}$ 에 대해 성립한다는 것이다. 여기서 $\epsilon$ 은 privacy budget, $\delta$ 는 failure probability이다. 이때 $\delta=0$ 이면 $\epsilon$-DP라고 한다.

DP 메커니즘으로 deterministic한 실함수 $f:\mathcal{D}\to \mathbb{R}$ 를 근사하는 일반적인 메커니즘은 **Gaussian mechanism**이다. 이는 다음과 같이 정의된다.

$$
\mathcal{M}(D) := f(D)  + \mathcal{N}(\mathbf{0},S_{f}^{2}\cdot \sigma^{2}\mathbf{I})
$$

여기서 $S_{f}$는 *sensitivity*<sup>민감도</sup>로 정의되며, $\left\vert f(D)- f(D')\right\vert$로 된다. $\sigma$는 noise의 scale을 나타낸다.


## Deep Learning Theory

파라미터 $\theta$에 대해, penalty를 나타내는 적절한 손실 함수 $\mathcal{L}$을 정의하면, empirical risk는 다음과 같이 주어진다.
$$
\mathcal{L}(\theta) = \frac{1}{N}\sum_{i}\mathcal{L}(\theta,x_{i})
$$

일반적으로 딥러닝에서는 헤시안 계산이 어렵기 때문에, SGD (Stochastic Gradient Descent) 알고리즘을 사용하는데 이는 전체 데이터로부터의 랜덤한 부분집합인 배치 $B$를 만들고 다음과 같이 계산한다.

$$
g_{B} = \frac{1}{\vert B\vert} \sum_{x\in B} \nabla_{\theta}\mathcal{L}(\theta,x)
$$

이는 그래디언트 $\nabla_{\theta}\mathcal{L}(\theta)$의 추정값으로 간주되며, 
업데이트 절차는 $-g_{B}$ 방향으로 주어진다.

딥러닝에서 DP를 부여하기 위한 핵심 포인트는 SGD의 각 스텝에서 DP를 만족시키도록 하는 방법을 생각할 수 있다. 이를 위해 논문에서는 다음과 같은 알고리즘을 제시한다.

## DP-SGD

DP-SGD 알고리즘은 다음과 같이 정의된다.

![](/assets/img/Pasted%20image%2020240130114952.png)

### Noise clipping

Algorithm 1가 DP를 보장한다는 것을 확인하기 위해서 그래디언트의 유계성이 필요한데, 이를 위해 논문에서는 **noise clipping**을 사용한다. 이는 그래디언트의 L2 norm이 $\sigma$를 넘지 않도록 하는 것이다. 이는 다음과 같이 정의된다.

$$
\bar g_{t}(x_i) = g_{t}(x_i) / \max(1, \left\Vert g_{t}(x_i)\right\Vert_{2}/C)
$$

여기서 $C$는 clipping threshold를 나타낸다.

## Moments Accountant

만약 다음과 같은 noise scale을 사용한다고 하자.

$$
\sigma= \frac{1}{\epsilon} \sqrt{2\log \frac{1.25}{\delta}}
$$

그러면 Algorithm 1의 각 스텝은 각 배치 $L$에 대해 $(\epsilon,\delta)$-DP를 만족한다. 따라서 privacy amplification theorem에 의해 전체 데이터셋에 대해 $(O(q\epsilon),q\delta)$-DP를 만족한다. 여기서 $q=L/N$은 배치의 샘플링 비율을 의미한다. 이러한 방법은 **strong composition theorem**을 사용한 것이다.

그러나 strong composition theorem은 항상 tight한 bound를 주지는 않는다. 이 논문에서는 **moments accountant**라는 더 강력한 계산 방법을 제시한다. 이는 다음과 같이 정의된다.


### Theorem 1

상수 $c_{1},c_{2}$가 존재하여, 샘플링 비율 $q=L/N$과 스텝 수 $T$가 주어졌을 때, 임의의 $\epsilon<c_{1}q^{2}T$에 대해 Algorithm 1은 아래 조건 하에서 $(\epsilon,\delta)$-DP를 만족한다.

$$
\sigma\ge c_{2} \frac{q\sqrt{T\log(1/\delta)}}{\epsilon}
$$

만약 strong composition theorem을 사용한다면 $\sigma = \Omega(q\sqrt{T\log(1/\delta)\log(T/\delta)}/\epsilon)$이다. 예를 들어, $q=0.01, \sigma=4, \delta=10^{-5}, T=10000$ 일 때, moments accountant를 사용하면 $\epsilon\approx 1.26$이 되지만, strong composition theorem을 사용하면 $\epsilon\approx 9.34$가 된다. 결과적으로 moments accountant를 사용하면 더 작은 $\epsilon$을 얻을 수 있다.

### Privacy Loss

Privacy loss는 다음과 같이 정의되는 확률변수이다.

$$
c(o;\mathcal{M},\text{aux},d,d') := \log \frac{\Pr (\mathcal{M}(\text{aux},d)=o)}{\Pr (\mathcal{M}(\text{aux},d')=o)}
$$

### Adaptive composition

일반적으로 머신러닝에서 DP 메커니즘은 adaptive하다. 즉, 메커니즘 여러개를 순차적으로 적용하는 경우가 많다. 이러한 경우에서는, $k$번째 메커니즘의 auxiliary input $\text{aux}$ 는 이전 메커니즘들의 output $o_{1:k-1}$에 의존한다.


### Log MGF

Privacy loss의 log moment generating function<sup>lmgf</sup>은 다음과 같이 정의된다.

$$
\alpha_\mathcal{M} (\lambda;\text{aux},d,d') := \log \mathrm{E}_{o\sim\mathcal{M}(\text{aux},d)}\left[\exp (\lambda c(o;\mathcal{M},\text{aux},d,d'))\right]
$$

또한, 다음과 같은 upper bound를 정의할 수 있다.

$$
\alpha_\mathcal{M} (\lambda) := \max_{\text{aux},d,d'}\log \mathrm{E}_{o\sim\mathcal{M}(\text{aux},d)}\left[\exp (\lambda c(o;\mathcal{M},\text{aux},d,d'))\right]
$$

### Theorem 2

#### Composability

메커니즘 $\mathcal{M}$ 이 sequential하게 정의되며, $$\mathcal{M}_{1},\cdots,\mathcal{M}_{k}$$로 구성된다고 하자. 이때, 각 element mechanism은 $$\mathcal{M}_{i}:\prod_{j=1}^{i-1} \mathcal{R}_{j}\times \mathcal{D}\to \mathcal{R}_{i}$$ 으로 정의된다. 그러면 $\forall \lambda$ 에 대해 다음이 성립한다.

$$
\alpha_\mathcal{M}(\lambda) \le \sum_{i=1}^{k}\alpha_\mathcal{M_{i}}(\lambda).
$$

#### Tail Bound

임의의 $\epsilon>0$에 대해, 메커니즘 $\mathcal{M}$이 다음을 만족하면 $(\epsilon,\delta)$-DP 메커니즘이다.


$$
\delta= \min_\lambda\exp(\alpha_\mathcal{M}(\lambda)-\lambda \epsilon).
$$

##### Proof

Markov inequality에 의해 다음이 성립한다.

$$
\begin{align}
\Pr_{o\sim \mathcal{M}(d)} (c(o) \geq \epsilon)  &= \Pr_{o\sim \mathcal{M}(d)} (\exp (\lambda c(o) \geq \exp(\lambda \epsilon))\\
&\le \frac{\mathrm{E}_{o}\exp(\lambda c(o))}{\exp(\lambda \epsilon)}\\
&\le \exp (\alpha-\lambda \epsilon).\tag{1}
\end{align}
$$

$B = \{o : c(o) \ge \epsilon\}$를 정의하면 임의의 $S$에 대해 다음 부등식이 성립한다.

$$
\begin{align}
\Pr(\mathcal{M}(d)\in S) &= \Pr (\mathcal{M}(d)\in S\cap B^{c}) + \Pr (\mathcal{M}(d)\in S\cap B)\\
&\le \exp(\epsilon)\Pr (\mathcal{M}(d') \in S) +\exp(\alpha-\lambda \epsilon)
\end{align}
$$

두번째 항에 대해서는 부등식 $(1)$을 사용하면 된다.

### Lemma. Composability of Gaussian mechanism

Suppose that $f:D\to \mathbb{R}^{p}$ with $\left\Vert f(\cdot)\right\Vert_{2}\le 1$. Let $\sigma \ge 1$ and $J$ be a sample from $\{1,\ldots,n\}$ where each element is chosen independently with probability $q < \frac{1}{16\sigma}$. Then for any positive integer $\lambda\le \sigma^{2}\log \frac{1}{q\sigma}$, the mechanism $\mathcal{M}(d) = \sum_{i\in J}f(d_{i}) + \mathcal{N}(0,\sigma^{2}\mathbf{I})$ satisfies

$$
\alpha_\mathcal{M}(\lambda) \le \frac{q^{2}\lambda(\lambda+1)}{(1-q)\sigma^{2}}+O(q^{3}\lambda^{3}/\sigma^{3}).
$$

위 보조정리와 Theorem 2를 사용하면 Theorem 1의 결과를 얻을 수 있다.

## DP to Moments bounds

DP 메커니즘의 log MGF는 다음과 같은 upper bound를 가진다. $\mathcal{M}$이 $\epsilon$-DP 메커니즘이라면, 임의의 $\lambda>0$ 에 대해 $\mathcal{M}$의 log MGF는 다음을 만족한다.


$$
\alpha_{\lambda}\le \lambda \epsilon(e^{\epsilon}-1)+\lambda^{2}\epsilon^{2}e^{2\epsilon}/2.
$$

### Proof

$Z$가 privacy loss random variable $c(\mathcal{M}(d))$ 이라고 하자. 그러면 $\epsilon$-DP 메커니즘 $\mathcal{M}$은 다음을 만족한다.

$$
\begin{align}
\mathrm{E}[Z] &\le \epsilon(\exp (\epsilon)-1)\\
\left\vert Z\right\vert &\le \epsilon,\text{ so that } \left\vert Z-\mu\right\vert \leq \epsilon\exp (\epsilon)
\end{align}
$$

이로부터 위 결과를 얻을 수 있다.


# References
- Abadi, M., Chu, A., Goodfellow, I., McMahan, H. B., Mironov, I., Talwar, K., & Zhang, L. (2016). Deep Learning with Differential Privacy. _Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security_, 308–318. [https://doi.org/10.1145/2976749.2978318](https://doi.org/10.1145/2976749.2978318)
- Dwork, C., Rothblum, G. N., & Vadhan, S. (2010). Boosting and Differential Privacy. _2010 IEEE 51st Annual Symposium on Foundations of Computer Science_, 51–60. [https://doi.org/10.1109/FOCS.2010.12](https://doi.org/10.1109/FOCS.2010.12)