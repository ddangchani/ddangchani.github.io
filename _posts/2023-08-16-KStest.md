---
title: Kolmogorov-Smirnov Test
tags:
- Statistics
- Normality Test
- Probability Theory
category: 
use_math: true
---
{% raw %}
# Kolmogorov-Smirnov Test

일반적으로 데이터사이언스에서 데이터의 정규성을 검정하고자 할 때, 샘플 수가 적은 경우 Shapiro-Wilk 검정을 이용하고 그렇지 않은 경우 Kolmogorov-Smirnov(줄여서 ks) 검정을 이용한다고 알려져 있다. 사실 콜모고로프-스미르노프 검정은 정규성을 검정한다기 보다는 주어진 데이터로부터 얻은 경험적 분포(empirical distribution)을 대상 확률분포 혹은 다른 경험분포와 비교하는 검정인 비모수 검정의 일종이다. 따라서 굳이 정규성 검정에 한정짓지 않고 사용가능하기도 하다. 이번 글에서는 콜모고로프-스미르노프 검정의 원리에 대해 자세히 다루어보고자 한다.

## Glivenko-Cantelli Theorem

콜모고로프-스미르노프 검정은 기본적으로 표본들로부터 얻은 경험적 분포가 표본의 원래 확률분포로 (표본의 개수가 많아질 수록)수렴한다는 원리에 기반하는데, 이 원리를 Glivenko-Cantelli 정리라고 한다. 이는 다음과 같다.

### Theorem
확률변수 $X_{1},\ldots,X_{n}$ 이 누적분포함수(cdf) $F$ 로부터의 iid 표본이라고 하자. 이때, 표본들로부터 다음과 같이 경험누적분포함수(empirical cdf) $\hat F_{n}$ 을 정의하자.


$$

\hat F_{n}(t) = \frac{1}{n}\sum_{i=1}^{n}I\{X_{i}\leq t\}


$$

그러면 다음이 성립한다.


$$

d_{K}(\hat F_{n},F)=\sup_{t}\vert \hat F_{n}(t)-F(t)\vert\to 0\;\;a.s. \tag{1}


$$

여기서 두 분포함수간의 거리 $d_{K}$ 를 Kolmogorov-Smirnov distance라고 하며, 이는 두 누적분포함수간의 거리 측도로 사용된다.

## Goodness of Fit test

앞선 Glivenko-Cantelli 정리의 결과 (1)은 분포함수간의 적합성 검정(GoF test)을 위한 토대를 제공한다. 어떤 분포함수 $F$ 가 특정 분포함수 $F_{0}$ 와 일치하는지 아닌지 검정하는 것을 우선 귀무가설 $H_{0}:F=F_{0}$ 으로 나타내자. 그러면 귀무가설 하에서 표본경험분포 $\hat F_{n}$ 는 Glivenko-Cantelli 정리에 의해 다음을 만족한다.


$$

d_{K}(\hat F_{n},F_{0})\to d_{K}(F,F_{0})\;\;\;a.s.


$$

이때, 우변은 $F=F_0$ 인 경우에만 0이 되므로, 귀무가설 하에서 통계량


$$

d_{K}(\hat F_{n},F_{0})


$$

은 작아지게 된다. 반대로 생각하면, 위 통계량이 커질수록 대립가설에 가까운 것이 되며 이를 바탕으로 기각역을 다음과 같이 설정할 수 있게 된다.


$$

d_{K}(\hat F_{n},F_{0})>c


$$

### Test statistic

Kolmogorov(1993), Smirnov(1944)에 의하면, 검정통계량 $d_{K}(\hat F_{n},F_0)$ 에 대해 다음과 같은 분포와 극한정리가 성립한다.

#### Theorem 1
임의의 연속인 누적분포함수 $F_0$에 대해 검정통계량의 누적분포함수는 다음과 같이 주어진다.

$$

P(d_{K}(\hat F_{n},F_{0})\leq t)=
\begin{cases}
0 & t\leq 0 \\
n!\prod_{i=1}^{n}\int_{\max\{0, \frac{n-i+1}{n}-t\}}^{u_{n-i+2}}du_{1}\cdots du_{n}& 0<t<1 \\
1&t\geq 1
\end{cases}


$$


#### Theorem 2
0보다 큰 $t$ 에 대해 다음이 성립한다.

$$

\lim_{n\to\infty}P(\sqrt{n}d_{K}(\hat F_{n},F_{0})\leq t)=1-2\sum_{j=1}^{\infty}(-1)^{j-1}e^{-2j^{2}t^{2}}


$$


### Confidence Interval

위 정리 1,2로부터 다음과 같이 콜모고로프-스미르노프 검정의 유의수준 $\alpha$ 신뢰구간을 설정할 수 있다.

$$

R_{n,1-\alpha}=\{F:\sqrt{n}\sup_{t}\vert \hat F_{n}(t)-F(t)\vert\leq s_{n,1-\alpha}\}


$$

## In Python

파이썬에서는 `scipy.stats` 패키지의 `kstest` 함수를 이용하여 콜모고로프-스미르노프 검정을 수행할 수 있다. 표본과 검정대상 확률분포(귀무가설)의 누적분포함수를 입력하면, 다음과 같이 검정통계량과 p-value를 출력하게 되며 $p<0.05$로 검정이 **기각** 되는 경우 표본의 확률분포와 대상 확률분포의 **유의미한 차이**가 존재함을 의미한다.

```python
import numpy as np 
from scipy import stats

data_normal = np.random.normal(0,10,1000)
data_uniform = np.random.uniform(-10,10,1000)

stats.kstest(data_normal, stats.norm(0,10).cdf)
# KstestResult(statistic=0.028788800830482852, pvalue=0.3715351689402041)
stats.kstest(data_uniform, stats.norm(0,10).cdf)
# KstestResult(statistic=0.15944162413229301, pvalue=1.1273769491585785e-22)

```

# References
- Jun Shao - Mathematical Statistics
- Lehmann - Testing Statistical Hypothesis



{% endraw %}